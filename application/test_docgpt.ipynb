{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc search + prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded settings: {'LLM_NAME': 'openai_chat', 'EMBEDDINGS_NAME': 'openai_text-embedding-ada-002', 'CELERY_BROKER_URL': 'redis://localhost:6379/0', 'CELERY_RESULT_BACKEND': 'redis://localhost:6379/1', 'MONGO_URI': 'mongodb://localhost:27017/docsgpt', 'MODEL_PATH': './models/gpt4all-model.bin', 'TOKENS_MAX_HISTORY': 150, 'API_URL': 'http://localhost:7091', 'API_KEY': None, 'EMBEDDINGS_KEY': None, 'AZURE_OPENAI_API_BASE': None, 'AZURE_OPENAI_API_VERSION': None, 'AZURE_DEPLOYMENT_NAME': 'text-davinci-003', 'AZURE_EMBEDDINGS_DEPLOYMENT_NAME': 'text-embedding-ada-002'}\n",
      "environ({'COMMAND_MODE': 'unix2003', 'HOME': '/Users/xshe', 'HOMEBREW_CELLAR': '/opt/homebrew/Cellar', 'HOMEBREW_PREFIX': '/opt/homebrew', 'HOMEBREW_REPOSITORY': '/opt/homebrew', 'INFOPATH': '/opt/homebrew/share/info:', 'LESS': '-R', 'LOGNAME': 'xshe', 'LSCOLORS': 'Gxfxcxdxbxegedabagacad', 'MANPATH': '/opt/homebrew/share/man::', 'MallocNanoZone': '0', 'OLDPWD': '/', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined', 'PAGER': 'cat', 'PATH': '/Users/xshe/.local/share/virtualenvs/docsgpt/bin:/Users/xshe/.local/bin:/Users/xshe/.pyenv/shims:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/opt/homebrew/opt/fzf/bin', 'PWD': '/', 'SHELL': '/bin/zsh', 'SHLVL': '1', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.9oF90G2jcW/Listeners', 'TMPDIR': '/var/folders/nf/xszf951s231fj4py486l32l00000gn/T/', 'USER': 'xshe', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_CODE_CACHE_PATH': '/Users/xshe/Library/Application Support/Code/CachedData/660393deaaa6d1996740ff4880f1bad43768c814', 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost', 'VSCODE_CWD': '/', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_IPC_HOOK': '/Users/xshe/Library/Application Support/Code/1.80-main.sock', 'VSCODE_NLS_CONFIG': '{\"locale\":\"en-us\",\"osLocale\":\"en-ca\",\"availableLanguages\":{},\"_languagePackSupport\":true}', 'VSCODE_PID': '1384', 'XPC_FLAGS': '0x0', 'XPC_SERVICE_NAME': '0', 'ZSH': '/Users/xshe/.oh-my-zsh', '_': '/Users/xshe/.local/share/virtualenvs/docsgpt/bin/python', '__CFBundleIdentifier': 'com.microsoft.VSCode', '__CF_USER_TEXT_ENCODING': '0x1F5:0x0:0x52', 'ELECTRON_RUN_AS_NODE': '1', 'VSCODE_L10N_BUNDLE_LOCATION': '', 'OPENAI_API_TYPE': 'azure', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'utf-8', 'AZURE_DEPLOYMENT_NAME': 'text-davinci-003', 'OPENAI_API_KEY': '705e82a9ce7b4c7bb68745e732c4dab4', 'VIRTUAL_ENV': '/Users/xshe/.local/share/virtualenvs/docsgpt', 'VITE_API_STREAMING': 'true', 'OPENAI_API_BASE': 'https://test-ron-openai.openai.azure.com/', 'PS1': '(docsgpt) ', 'AZURE_EMBEDDINGS_DEPLOYMENT_NAME': 'text-embedding-ada-002', 'OPENAI_API_VERSION': '2022-12-01', 'VIRTUAL_ENV_PROMPT': '(docsgpt) ', 'LC_CTYPE': 'UTF-8', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE'})\n"
     ]
    }
   ],
   "source": [
    "from app import get_docsearch\n",
    "\n",
    "\n",
    "history = [\n",
    "    {\n",
    "        \"prompt\": \"who are you?\",\n",
    "        \"response\": \"Hi there! I'm IntegrateAIAssistant, a friendly and helpful AI assistant by Integrate.ai. I'm here to help you with documents. If you have any questions, please let me know!\"\n",
    "    }\n",
    "]\n",
    "data = {\n",
    "        \"question\": \"How do I get started?\",\n",
    "        \"history\": history,\n",
    "        \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "        \"embeddings_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "        \"vectorstore_path\": \"\"\n",
    "    }\n",
    "\n",
    "question = data[\"question\"]\n",
    "history = data[\"history\"]\n",
    "api_key = data[\"api_key\"]\n",
    "embeddings_key = data[\"embeddings_key\"]\n",
    "\n",
    "\n",
    "# loading the index and the store and the prompt template\n",
    "# Note if you have used other embeddings than OpenAI, you need to change the embeddings\n",
    "docsearch = get_docsearch(data[\"vectorstore_path\"], embeddings_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever()\n",
    "retriever.search_kwargs = {\"k\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='\\n\\nRequirements\\n\\nThis section outlines the setup steps required to configure your working environment. Steps that are performed in the AWS platform are not explained in detail. Refer to the AWS documentation as needed. \\n\\nThe requirements are tool-agnostic - that is, you can complete the steps through the AWS console, or through a tool such as Terraform or AWS CloudFormation. \\n\\n', metadata={'title': 'inputs/iai_doc/aws-batch-manual.md'}),\n",
       "  0.46205106),\n",
       " (Document(page_content='\\n\\nInstall components\\n\\nInstall the integrate.ai command-line tool (CLI), the SDK, and the client. For detailed instructions, see .\\n\\n', metadata={'title': 'inputs/iai_doc/user-auth.md'}),\n",
       "  0.49679202),\n",
       " (Document(page_content='\\n\\nRunning a training server on AWS Fargate\\n\\nSet up the Fargate environment, as described in .\\n\\n', metadata={'title': 'inputs/iai_doc/aws-fargate-sdk.md'}),\n",
       "  0.50277495),\n",
       " (Document(page_content='\\n\\nDeployment Scenarios\\n\\n\\n', metadata={'title': 'inputs/iai_doc/deployment.md'}),\n",
       "  0.5043397),\n",
       " (Document(page_content='\\n\\nAWS Batch and Fargate Manual Setup\\n\\n', metadata={'title': 'inputs/iai_doc/aws-batch-manual.md'}),\n",
       "  0.51007426),\n",
       " (Document(page_content='\\n\\nRun the training server\\n\\nThe SDK provides a taskgroup and taskbuilder object to simplify the process of creating and managing Fargate and AWS Batch tasks. \\n\\n', metadata={'title': 'inputs/iai_doc/aws-fargate-sdk.md'}),\n",
       "  0.51035047),\n",
       " (Document(page_content='\\n\\nManaged Cloud-hosted\\n\\nFocused on model building, they don’t have IT team. They need job to run when they execute. Set up task runners - make sure AWS is up and running, there’s an ecr that can store the client image, and your batch job has permission to access your data. \\nWe set up server and manage it. \\n\\n\\n', metadata={'title': 'inputs/iai_doc/deployment.md'}),\n",
       "  0.5121994),\n",
       " (Document(page_content='\\n\\nWeb app\\n\\nThe web app is a tenant management portal for customers. Through the web app, you can manage system access (via user tokens), create and manage task runners, and review and configure session information. \\n\\n', metadata={'title': 'inputs/iai_doc/overview.md'}),\n",
       "  0.51305187),\n",
       " (Document(page_content='\\n\\nintegrate.ai HFL Gradient Boosting Methods Sample Notebook\\n\\n', metadata={'title': 'inputs/iai_sample_notebook/integrateai_api_gbm.md'}),\n",
       "  0.51699525),\n",
       " (Document(page_content='\\n\\nSet up the dataset\\n\\nCreate one or more S3 buckets to contain the dataset(s). The URL for the dataset is a required parameter for the SDK. \\nIf necessary, copy the data to your S3 bucket, as shown in the example below.\\n\\n```bash\\naws s3 cp  s3:// --recursive\\n```\\n\\nNote: Only S3 is supported.\\n\\n\\n\\n \\n\\nCreate batch roles and policies\\n\\nThis guide describes in brief how to create and manage roles and policies through the AWS IAM service console. The JSON configuration is also provided for those using Terraform or other tools. \\n\\nYou can create roles from the Roles link under Access Management in IAM. \\n\\nNote: For the sample code that follows, replace any variable placeholders (such as ) with the correct information for your environment before attempting to use it.\\n\\n\\nEC2 Instance Role\\nClick Create Role.\\nSelect AWS Service.\\nSelect EC2. \\nClick Next.\\nIn the Permissions policies search box, type AmazonEC2ContainerServiceforEC2. This is the ARN. \\nSelect this policy and click Next. \\nProvide a meaningful name for the role. \\nReview the configuration and compare it to the example below.\\nClick Create role. \\n\\nBatch Service Role\\nCreate an associated instance profile and batch service role.\\nClick Create Role.\\nSelect AWS Service.\\nSelect Batch from the drop-down list, then select Batch. \\nClick Next.\\nOn the Permissions policies page, click Next. \\nProvide a meaningful name for the role. \\nReview the configuration and compare it to the example below.\\nClick Create role. \\n\\nECS Task Role (Job Role) with CloudWatch and S3 policies\\nThis role requires access to the S3 bucket containing your data. It requires the ECS task role policy and an S3 access policy.\\nClick Create Role.\\nSelect AWS Service.\\nSelect Elastic Container Service from the drop-down list.\\nSelect Elastic Container Service Task.  \\nClick Next.\\nOn the Add Permissions page, click Create policy. This opens a Policies page in a second browser window to allow you to create policies and return to your role to attach them. \\nOn the Create policy page, select the JSON tab and paste the following, with your  and  filled in.\\n\\n9. Click Next: Tags, then click Next: Review.\\n10. Provide a meaningful name for the policy. \\n11. Click Create policy. \\nAdd an S3 policy. \\n Click Create policy.\\nOn the Create policy page, select the JSON tab and paste the following, with the name of  filled in.\\n\\nThe S3 policy on the ECS task role restricts the Job Definition to the S3 buckets that are referenced. To restrict data access further, consider creating different Job Definitions that access different S3 buckets.\\nClick Next: Tags, then click Next: Review. \\nProvide a meaningful name for the policy. \\nClick Create policy. \\nAdd policies to the role\\nReturn to the Add permissions page in the previous browser window. \\nUse the Permissions policies search box to search for and select the names of the two policies you just created. \\nClick Next.\\nProvide a meaningful name for the role, such as ecs-task-role. \\nClick Create role. \\nECS Execution Role with ECR, CloudWatch, and SSM policies\\nThis role gives the batch job access to ECR and SSM. It requires the ECS task role policy and ECR, CloudWatch, and SSM policies.\\nClick Create Role.\\nSelect AWS Service.\\nSelect Elastic Container Service from the drop-down list.\\nSelect Elastic Container Service Task.  \\nClick Next.\\nIn the Permissions policies search box, type AmazonECSTaskExecutionRolePolicy.\\nSelect this policy, then click Next.\\nProvide a meaningful name for the role, such as ecs-execution-role.\\nScroll down to Step 2: Add permissions and click Edit.\\nClick Create policy. \\nOn the Create policy page, select the JSON tab and paste the following:\\n\\nClick Next: Tags and then click Next: Review.\\nProvide a meaningful name for the policy. \\nClick Create policy.\\nIn the Create role browser window, in the Permissions policies search box, type the name of the policy you just created. Note: you may have to click the Refresh button beside the Create policy button to make the new policy appear. \\nSelect the policy. \\nClick Next. \\nRepeat the process above to add an SSM policy. Fill in your  and  information. \\n\\nAdd the policy to your ECS Execution role. \\nClick Next.\\nClick Create Role.\\nSDK User Role \\nThe role and permissions required to set up and configure the environment are different than the permissions required to start an integrate.ai client batch job using the integrate.ai SDK. \\nThe end user of the SDK requires, at minimum, permission to submit a batch job using the job queue and job definition created earlier, and permission to describe jobs. \\nAny additional permissions required depend on your application. For example, you may give the user the ability to access the SSM parameter set earlier, so that they can pull the integrate.ai access token and use it to manage sessions with the integrate.ai SDK.\\n\\n\\n\\n\\n', metadata={'title': 'inputs/iai_doc/aws-batch-manual.md'}),\n",
       "  0.5261638),\n",
       " (Document(page_content='\\n\\nCreate and start HFL tasks manually\\n\\n\\n```python\\nfls = tb.fls(subnet_id, security_group, storage_path=model_storage, client=client)\\nfls.set_session(training_session)\\nfls_server = fls.start()\\n```\\n\\n\\n```python\\nfls_server.status()\\n```\\n\\n\\n```python\\nhfl = tb_batch.hfl(train_path=train_path1, test_path=test_path, vcpus=\"2\", memory=\"16384\", client=client)\\nhfl.set_session(training_session)\\n```\\n\\n\\n```python\\nhfl_context = hfl.start()\\n```\\n\\n\\n```python\\nhfl_context.status()\\n```\\n\\n', metadata={'title': 'inputs/iai_sample_notebook/integrateai_local_batch_fargate.md'}),\n",
       "  0.5330721),\n",
       " (Document(page_content='\\n\\nAuthentication\\n\\nComplete the steps to create an IAI access token, hereafter referred to as .\\n\\nOn the AWS CLI, set the token as a parameter for your SSM agent. SSM handles getting and using the token as needed for the batch session.\\n\\n```python\\naws ssm put-parameter --name iai-token --value  --type SecureString\\n```\\n\\nExample response:\\n\\n```\\n{\\n    \"Version\": 1,\\n    \"Tier\": \"Standard\"\\n}\\n```\\n\\n \\n\\nAbout \"secrets\"\\n\\nIn order for the batch job to access the integrate.ai JWT through SSM it needs to be set in the job definition secrets configuration. \\nSet the name of the secret to IAI_TOKEN to create the IAI_TOKEN environment variable that the docker client uses to authenticate with the session. \\nThe valueFrom is the SSM key that contains the integrate.ai access token. If you are running the batch job in the same region that the SSM parameter was created in, pass in the name of the SSM parameter. If the SSM parameter is in a different region, pass in the SSM parameter ARN. \\nTo have different tokens for different user groups, you must have a different batch job definition for each token.\\nThe command and parameter values are examples only. They are overwritten when starting a batch job with the SDK. \\nBatch job configuration is now complete. \\n\\n\\n \\n\\nCreate an AWS KMS Key\\n\\nIf you do not already have one, define a symmetric key for encryption and decryption in AWS KMS. The IAI server uses the ID of your key to retrieve the IAI access token through SSM. \\n\\nIn the KMS console, click Create a Key.\\nKeep the default settings for Symmetric and Encrypt and decrypt. Click Next.\\nType an Alias for the key. Click Next.\\nSelect one or more Key administrators and click Next.\\nSelect one or more IAM Users and/or Roles to grant access to the key. \\nThe SDK User IAM Role must have GenerateDataKey and Encrypt permissions. \\nThe Fargate Task and/or Batch job roles must have Decrypt permission.\\nClick Next, then click Finish. \\nMake a note of the Key ID. This parameter is required as part of the training session definition. \\n\\n\\n', metadata={'title': 'inputs/iai_doc/aws-batch-manual.md'}),\n",
       "  0.5360047),\n",
       " (Document(page_content='\\n\\nRun Training Server on AWS Fargate\\n\\n', metadata={'title': 'inputs/iai_sample_notebook/integrateai_fargate_server.md'}),\n",
       "  0.5362798),\n",
       " (Document(page_content='\\n\\nintegrate.ai API Sample Notebook\\n\\n', metadata={'title': 'inputs/iai_sample_notebook/integrateai_api.md'}),\n",
       "  0.5385523),\n",
       " (Document(page_content='\\n\\nintegrate.ai API Sample Notebook\\n\\n', metadata={'title': 'inputs/iai_sample_notebook/integrateai_eda_intersect_batch.md'}),\n",
       "  0.5385523),\n",
       " (Document(page_content='\\n\\nOpen sample notebook\\n\\nOpen the Authentication sample notebook (integrateai_auth.ipynb) located in the SDK package.\\n\\n`..integrate_ai_sdk/src/integrate_ai_sdk/sample_packages/sample_notebook/ `\\n\\nThe notebook provides sample code that demonstrates how to use the SDK to generate users and tokens.\\n\\n', metadata={'title': 'inputs/iai_doc/user-auth.md'}),\n",
       "  0.54193544),\n",
       " (Document(page_content='\\n\\nPlatform Overview\\n\\nThe integrate.ai SaaS platform consists of 3 main components:\\n1. A federated learning server and backend.\\n2. A web app for workspace administration.\\n3. A robust API and SDK that support federated analytical orchestration.\\n\\n', metadata={'title': 'inputs/iai_doc/overview.md'}),\n",
       "  0.5422398),\n",
       " (Document(page_content='\\n\\nBest practices for setting up S3 data:\\n\\n* Use EC2 instances for faster setup and greater flexibility to run experiments quickly. We recommend setting up a memory optimized instance, like an r4.large.\\n* Configure read-only AWS permissions for the dataset.\\n\\nSee  for a tutorial that includes using data hosted in S3 buckets.\\n\\n', metadata={'title': 'inputs/iai_doc/data-requirements.md'}),\n",
       "  0.5425286),\n",
       " (Document(page_content='\\n\\nStart an EDA Session using IAI client\\nFollow the documentation on directions for how to install the integrate_ai package and the sample data.\\nUnzip the sample data to your `~/Downloads` directory, otherwise update the `data_path` below to point to the sample data.\\n\\n\\n```python\\n', metadata={'title': 'inputs/iai_sample_notebook/integrateai_eda_intersect_batch.md'}),\n",
       "  0.5452961),\n",
       " (Document(page_content=\"\\n\\nSpecify the name of your cluster, task definition and network parameters\\nfargate_cluster = ''\\ntask_def = ''\\nsubnet_id = ''\\nsecurity_group = ''\\ntrain_path1 = '{train path 1}'\\ntrain_path2 = '{train path 2}'\\ntest_path = '{test path}'\\njob_queue= ''\\njob_def=''\\nmodel_storage='{model storage path}'\\n```\\n\\nWith the credentials and variables defined, you can now use the SDK to run the training server on AWS Fargate.\\n\\n\", metadata={'title': 'inputs/iai_doc/aws-fargate-sdk.md'}),\n",
       "  0.5456402)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch.similarity_search_with_score(query=data[\"question\"], k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\nRequirements\\n\\nThis section outlines the setup steps required to configure your working environment. Steps that are performed in the AWS platform are not explained in detail. Refer to the AWS documentation as needed. \\n\\nThe requirements are tool-agnostic - that is, you can complete the steps through the AWS console, or through a tool such as Terraform or AWS CloudFormation. \\n\\n', metadata={'title': 'inputs/iai_doc/aws-batch-manual.md'}),\n",
       " Document(page_content='\\n\\nInstall components\\n\\nInstall the integrate.ai command-line tool (CLI), the SDK, and the client. For detailed instructions, see .\\n\\n', metadata={'title': 'inputs/iai_doc/user-auth.md'}),\n",
       " Document(page_content='\\n\\nRunning a training server on AWS Fargate\\n\\nSet up the Fargate environment, as described in .\\n\\n', metadata={'title': 'inputs/iai_doc/aws-fargate-sdk.md'}),\n",
       " Document(page_content='\\n\\nDeployment Scenarios\\n\\n\\n', metadata={'title': 'inputs/iai_doc/deployment.md'}),\n",
       " Document(page_content='\\n\\nAWS Batch and Fargate Manual Setup\\n\\n', metadata={'title': 'inputs/iai_doc/aws-batch-manual.md'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(data[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=os.environ[\"AZURE_DEPLOYMENT_NAME\"],\n",
    "    temperature=0,\n",
    "    model_kwargs={\n",
    "        \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "        \"api_base\": os.environ[\"OPENAI_API_BASE\"],\n",
    "        \"api_type\": os.environ[\"OPENAI_API_TYPE\"],\n",
    "    },\n",
    "    openai_api_version=os.environ[\"OPENAI_API_VERSION\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    ")\n",
    "from app import chat_combine_template, settings\n",
    "\n",
    "\n",
    "messages_combine = [SystemMessagePromptTemplate.from_template(chat_combine_template)]\n",
    "if history:\n",
    "    tokens_current_history = 0\n",
    "    # count tokens in history\n",
    "    history.reverse()\n",
    "    for i in history:\n",
    "        if \"prompt\" in i and \"response\" in i:\n",
    "            tokens_batch = llm.get_num_tokens(i[\"prompt\"]) + llm.get_num_tokens(i[\"response\"])\n",
    "            if tokens_current_history + tokens_batch < settings.TOKENS_MAX_HISTORY:\n",
    "                tokens_current_history += tokens_batch\n",
    "                messages_combine.append(HumanMessagePromptTemplate.from_template(i[\"prompt\"]))\n",
    "                messages_combine.append(AIMessagePromptTemplate.from_template(i[\"response\"]))\n",
    "messages_combine.append(HumanMessagePromptTemplate.from_template(\"{question}\"))\n",
    "\n",
    "p_chat_combine = ChatPromptTemplate.from_messages(messages_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are IntegrateaiAssistant, friendly and helpful AI assistant by Integrate.ai that provides help with documents. You give thorough answers with code examples if possible. If there is no code example available, don't try to make up any code.\n",
      "Use the following pieces of context to help answer the users question. If its not relevant to the question, just say that there is not enough information, don't try to make up an answer.\n",
      "When using code examples, use the following format:\n",
      "```(language)\n",
      "(code)\n",
      "```\n",
      "----------------\n",
      "my summary\n",
      "Human: who are you?\n",
      "AI: Hi there! I'm IntegrateAIAssistant, a friendly and helpful AI assistant by Integrate.ai. I'm here to help you with documents. If you have any questions, please let me know!\n",
      "Human: my question\n"
     ]
    }
   ],
   "source": [
    "print(p_chat_combine.format(question=\"my question\", summaries=\"my summary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "\n",
      "\n",
      "Requirements\n",
      "\n",
      "This section outlines the setup steps required to configure your working environment. Steps that are performed in the AWS platform are not explained in detail. Refer to the AWS documentation as needed. \n",
      "\n",
      "The requirements are tool-agnostic - that is, you can complete the steps through the AWS console, or through a tool such as Terraform or AWS CloudFormation. \n",
      "\n",
      "\n",
      "Question: How do I get started?\n",
      "Relevant text, if any:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "\n",
      "\n",
      "Install components\n",
      "\n",
      "Install the integrate.ai command-line tool (CLI), the SDK, and the client. For detailed instructions, see .\n",
      "\n",
      "\n",
      "Question: How do I get started?\n",
      "Relevant text, if any:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "\n",
      "\n",
      "Running a training server on AWS Fargate\n",
      "\n",
      "Set up the Fargate environment, as described in .\n",
      "\n",
      "\n",
      "Question: How do I get started?\n",
      "Relevant text, if any:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "\n",
      "\n",
      "Deployment Scenarios\n",
      "\n",
      "\n",
      "\n",
      "Question: How do I get started?\n",
      "Relevant text, if any:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following portion of a long document to see if any of the text is relevant to answer the question. \n",
      "Return any relevant text verbatim.\n",
      "\n",
      "\n",
      "AWS Batch and Fargate Manual Setup\n",
      "\n",
      "\n",
      "Question: How do I get started?\n",
      "Relevant text, if any:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are IntegrateaiAssistant, friendly and helpful AI assistant by Integrate.ai that provides help with documents. You give thorough answers with code examples if possible. If there is no code example available, don't try to make up any code.\n",
      "Use the following pieces of context to help answer the users question. If its not relevant to the question, just say that there is not enough information, don't try to make up an answer.\n",
      "When using code examples, use the following format:\n",
      "```(language)\n",
      "(code)\n",
      "```\n",
      "----------------\n",
      " \n",
      "This section outlines the setup steps required to configure your working environment. Steps that are performed in the AWS platform are not explained in detail. Refer to the AWS documentation as needed. The requirements are tool-agnostic - that is, you can complete the steps through the AWS console, or through a tool such as Terraform or AWS CloudFormation.\n",
      "\n",
      " Install the integrate.ai command-line tool (CLI), the SDK, and the client. For detailed instructions, see .\n",
      "\n",
      " Set up the Fargate environment, as described in .\n",
      "\n",
      " No relevant text.\n",
      "\n",
      " No relevant text.\n",
      "Human: who are you?\n",
      "AI: Hi there! I'm IntegrateAIAssistant, a friendly and helpful AI assistant by Integrate.ai. I'm here to help you with documents. If you have any questions, please let me know!\n",
      "Human: How do I get started?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "\n",
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"map_reduce\", combine_prompt=p_chat_combine, verbose=True)\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "chat_history = []\n",
    "result = chain({\"question\": question, \"chat_history\": chat_history})\n",
    "# generate async with async generate method\n",
    "# result = run_async_chain(chain, question, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How do I get started?',\n",
       " 'chat_history': [],\n",
       " 'answer': \"\\nAI: To get started, you'll need to install the integrate.ai command-line tool (CLI), the SDK, and the client. For detailed instructions, see the documentation. After that, you'll need to set up the Fargate environment, as described in the documentation.\",\n",
       " 'source_documents': [Document(page_content='\\n\\nRequirements\\n\\nThis section outlines the setup steps required to configure your working environment. Steps that are performed in the AWS platform are not explained in detail. Refer to the AWS documentation as needed. \\n\\nThe requirements are tool-agnostic - that is, you can complete the steps through the AWS console, or through a tool such as Terraform or AWS CloudFormation. \\n\\n', metadata={'title': 'inputs/iai_doc/aws-batch-manual.md'}),\n",
       "  Document(page_content='\\n\\nInstall components\\n\\nInstall the integrate.ai command-line tool (CLI), the SDK, and the client. For detailed instructions, see .\\n\\n', metadata={'title': 'inputs/iai_doc/user-auth.md'}),\n",
       "  Document(page_content='\\n\\nRunning a training server on AWS Fargate\\n\\nSet up the Fargate environment, as described in .\\n\\n', metadata={'title': 'inputs/iai_doc/aws-fargate-sdk.md'}),\n",
       "  Document(page_content='\\n\\nDeployment Scenarios\\n\\n\\n', metadata={'title': 'inputs/iai_doc/deployment.md'}),\n",
       "  Document(page_content='\\n\\nAWS Batch and Fargate Manual Setup\\n\\n', metadata={'title': 'inputs/iai_doc/aws-batch-manual.md'})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def query(question, url=\"http://0.0.0.0:7091/api/answer\", history=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"question\": question,\n",
    "        \"history\": history,\n",
    "        \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "        \"embeddings_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "    }\n",
    "\n",
    "    res = requests.post(url=url, data=json.dumps(payload), headers=headers)\n",
    "    res_json = res.json()\n",
    "    display(Markdown(res_json[\"answer\"]))\n",
    "    return res_json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAI DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = query(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = query(\"How do I get started?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"How do I deploy this in AWS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"How do I use a custom model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"how do I generate a non-admin token?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"How do I renew my token?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"How do I set my differential privacy parameter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"If I wanted to try multi-client training, where one client has Y, X1 and another client has X2 features, how would I setup the data schema and client train commands?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"I got Error code 401. What does it mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"give me an example of running a session on AWS BATCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"can you give the template for building a custom model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"what evaluation metrics are supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"what does GLM mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"how do I train a GLM with integrateai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"how to create an EDA session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"give me an example of data config for PRL sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"which strategies are currently supported for HFL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"what is a VFL session\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"what is pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"how to load parquet files?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"how to load parquet files directly with pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"gimme an example of computing the moving average of all columns in a dataframe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iai_local_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
