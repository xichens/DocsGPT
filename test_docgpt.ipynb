{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def query(question, url=\"http://0.0.0.0:7091/api/answer\", history=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"question\": question,\n",
    "        \"history\": history,\n",
    "        \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "        \"embeddings_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "    }\n",
    "\n",
    "    res = requests.post(url=url, data=json.dumps(payload), headers=headers)\n",
    "    display(Markdown(res.json()[\"answer\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAI DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "System: To get started, you will need to install the integrate.ai command-line tool (CLI), the SDK, and the client. For detailed instructions, please refer to the documentation provided. After that, you will need to set up the Fargate environment, as described in the documentation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"How do I get started?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "DocsGPT: To deploy this in AWS, you will need to set up a task runner using AWS Batch and Fargate. You can find instructions for manual setup in the AWS documentation here: https://docs.aws.amazon.com/batch/latest/userguide/Batch_Manual_Setup.html. Once you have set up the task runner, you will need to make sure that AWS is up and running, that there is an ECR that can store the client image, and that your batch job has permission to access your data. Finally, you will need to set up and manage the server."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"How do I deploy this in AWS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "DocsGPT: To use a custom model, you will need to create a custom package and define a model class. You can then choose a name for your custom model, and set the path for the model and data configurations. Note that the name for your custom model **must be unique**. This means that the name for your custom model cannot already be in the Package Name column of the Custom Models Packages Table in the Model Library Page of the UI. \n",
       "\n",
       "For example, you can use the following code to create a custom model using the model class defined in a custom package:\n",
       "```python\n",
       "from integrate_ai_sdk.sample_packages.lstmTagger.model import LSTMTagger\n",
       "\n",
       "model = LSTMTagger(embedding_dim=4, hidden_dim=3, output_size=4, vocab_size=9)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"How do I use a custom model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "You can generate a non-admin token by following these steps: \n",
       "1. Log in to your integrate.ai account on the web. \n",
       "2. On the Dashboard, click Generate Access Token.\n",
       "3. Select the Non-Admin option.\n",
       "4. Copy the access token and save it to a secure location."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"how do I generate a non-admin token?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "System: You can renew your token by setting the 'renewable' parameter to True when creating the token. For example, in Python:\n",
       "```Python\n",
       "token = jwt.encode({'renewable': True}, secret_key)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"How do I renew my token?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "DocsGPT: You can set your differential privacy parameter when you create a session in integrate.ai. For example, in Python you can use the following code:\n",
       "```Python\n",
       "session = integrate.ai.Session(\n",
       "    privacy_parameter=0.1\n",
       ")\n",
       "```\n",
       "This will set the privacy parameter to 0.1."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"How do I set my differential privacy parameter?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "DocsGPT: To set up multi-client training with one client having Y, X1 features and another client having X2 features, you will need to create two separate training datasets. The first dataset should contain the Y, X1 features and the second dataset should contain the X2 features. You can then use the following code to set up the client train commands: \n",
       "\n",
       "```Python\n",
       "train_path1 = \"s3://iai-client.sample-data-e2e.integrate.ai/train_silo0.parquet\"\n",
       "train_path2 = \"s3://iai-client.sample-data-e2e.integrate.ai/train_silo1.parquet\"\n",
       "\n",
       "client_1 = subprocess.Popen(\n",
       "    f\"iai client train --token {IAI_TOKEN} --session {training_session.id} --train-path {train_path1} --test-path {data_path}/test.parquet --batch-size 1024 --client-name client-1 --remove-after-complete\",\n",
       "    shell=True,\n",
       "    stdout=subprocess.PIPE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"If I wanted to try multi-client training, where one client has Y, X1 and another client has X2 features, how would I setup the data schema and client train commands?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "?\n",
       "\n",
       "System: Error code 401 means Unauthorized - Your API key is wrong."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"I got Error code 401. What does it mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "DocsGPT: You can use the following code example to run a session on AWS Batch:\n",
       "\n",
       "```Python\n",
       "import boto3\n",
       "\n",
       "# Create a Batch client\n",
       "batch = boto3.client('batch')\n",
       "\n",
       "# Create a job queue\n",
       "job_queue = batch.create_job_queue(\n",
       "    jobQueueName='my-job-queue',\n",
       "    state='ENABLED'\n",
       ")\n",
       "\n",
       "# Create a job definition\n",
       "job_definition = batch.register_job_definition(\n",
       "    jobDefinitionName='my-job-definition',\n",
       "    type='container',\n",
       "    containerProperties={\n",
       "        'image': 'integrateai/api-sample-notebook:latest',\n",
       "        'vcpus': 1,\n",
       "        'memory': 1024,\n",
       "        'command': [\n",
       "            'python',\n",
       "            'run_client.py'\n",
       "        ]\n",
       "    }\n",
       ")\n",
       "\n",
       "# Submit a job\n",
       "job = batch.submit_job(\n",
       "    jobName='my-job',\n",
       "    jobQueue=job_queue['jobQueueName'],\n",
       "    jobDefinition=job_definition['jobDefinitionName']\n",
       ")\n",
       "``"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"give me an example of running a session on AWS BATCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "?\n",
       "\n",
       "Sure! Here is the template for building a custom model:\n",
       "\n",
       "```python\n",
       "class MyCustomModel(Model):\n",
       "    def __init__(self, config):\n",
       "        super(MyCustomModel, self).__init__(config)\n",
       "        # Add your custom model code here\n",
       "        # ...\n",
       "    \n",
       "    def forward(self, inputs):\n",
       "        # Add your custom model code here\n",
       "        # ...\n",
       "        return outputs\n",
       "```\n",
       "\n",
       "Remember to name your custom model class and the associated .json file with the same name. The name must be unique and contain no spaces, no special characters, and all lowercase characters."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"can you give the template for building a custom model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " by the SessionMetrics class?\n",
       "\n",
       "The SessionMetrics class supports the following evaluation metrics: accuracy, precision, recall, F1 score, loss (cross-entropy for classification and logistic tasks, mean squared error for regression and normal tasks, and unit deviance for Poisson, Gamma, and Inverse Gaussian tasks), and ROC-AUC and R2 score for all tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"what evaluation metrics are supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "?\n",
       "\n",
       "System: GLM stands for Generalized Linear Model. It is a model class that supports a variety of regression models, such as linear regression, logistic regression, Poisson regression, gamma regression and inverse Gaussian regression models. For example, in Python, you can use the statsmodels library to fit a GLM:\n",
       "\n",
       "```Python\n",
       "import statsmodels.api as sm\n",
       "model = sm.GLM(y, X)\n",
       "results = model.fit()\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"what does GLM mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "?\n",
       "\n",
       "System: You can train a GLM with integrateai by using the iai_glm model. This model treats GLMs as a special case of single-layer neural nets with particular output activation functions. Here is an example of how to use the iai_glm model in Python:\n",
       "\n",
       "```Python\n",
       "from integrateai.models import iai_glm\n",
       "\n",
       "model = iai_glm(input_dim=10, output_dim=1)\n",
       "model.fit(X_train, y_train)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"how do I train a GLM with integrateai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "System: To create an EDA session, you must first create a session, the same as you would for training a model. In this case, to configure the session, you must specify either the dataset_config, or num_datasets argument. Using a dataset_config file: The dataset_config file is a configuration file that maps the name of one or more datasets to the columns to be pulled. Dataset names and column names are specified as key-value pairs in the file. For each pair, the keys are dataset names that are expected for the EDA analysis. The values are a list of corresponding columns. The list of columns can be specified as column names (strings), column indices (integers), or a blank list to retrieve all columns from that particular dataset. If a dataset name is not included in the configuration file, all columns from that dataset are used by default.\n",
       "\n",
       "To create an EDA session, we specify a `dataset_config` dictionary indicating the columns to explore for each dataset. Here the empty list `[]` means to include all columns. \n",
       "For example:\n",
       "```python\n",
       "eda_session = client.create_eda_session(\n",
       "    name=\"Testing notebook -"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"how to create an EDA session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "System: Sure, here is an example of a PRL data config for a session with two clients: \n",
       "```python\n",
       "prl_data_config = {\n",
       "    \"clients\": {\n",
       "        \"passive_client\": {\"id_columns\": [\"id\"]},\n",
       "        \"active_client\": {\"id_columns\": [\"id\"]},\n",
       "    }\n",
       "}\n",
       "```\n",
       "This data config specifies that the two clients are providing data and that the \"id\" column in any provided datasets will be used to link the two datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"give me an example of data config for PRL sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "?\n",
       "\n",
       "System: Currently, the iai_ffnet model supports classification and regression for HFL. Additionally, the integrate.ai HFL Gradient Boosting Methods are also supported."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"which strategies are currently supported for HFL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "?\n",
       "\n",
       "A VFL session is a type of machine learning session used to link two datasets together. It is used to create a predictive model that can be used to make predictions about future data. In a VFL session, the training data is used to create a model that can be used to make predictions about the test data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(\"what is a VFL session\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default (Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"what is pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"how to load parquet files?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"how to load parquet files directly with pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"gimme an example of computing the moving average of all columns in a dataframe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iai_local_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
